---
title: "Assignment 3"
author: "MDA 9155 - Instructor: Dr. Camila de Souza"
date: "Winter 2025"
output: pdf_document
header-includes:
- \usepackage[fontsize=12pt]{scrextend}
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(faraway)
library(ggplot2)
library(lme4)
library(gridExtra)
library(sm)
library(pbkrtest)
```

\textbf{Student name: Yun Kyaw}

\textbf{Student number: 251102171}

## Question 1
### a)
$$ 
\begin{aligned}
f(y) &= \lambda exp(-\lambda y) \\
logLik(y) &= ln(\lambda) (-\lambda y) \\
&= exp[ln(\lambda) - \lambda y] \\
&= exp[y(-\lambda) - (-ln(\lambda))] \\
\implies \theta &= -\lambda \\
\phi &= 1 \\
a() &= 1 \\
b() &= -ln(\lambda)  = -ln(\theta) \\
c() &= 0
\end{aligned}
$$


\newpage
### b)
$$
\begin {aligned}
link &= b'(0) = -\frac{1}{\theta} = -\frac{1}{\mu} \\
V(\mu) &= \mu^2
\end {aligned}
$$

\newpage
### c)
if $\mu$ = 0 then issues may arise as $\frac{1}{0}$ is not valid. 

\newpage
### d)
$\chi^2$ test because there is a fixed, known dispersion parameter. 

\newpage
### e)
$D = 2\sum[y_i log(\frac{y_i}{\hat{\mu_i}}) - (y_i - \hat{\mu_i})]$

\newpage

## Question 2
```{r}
data(gala, package = "faraway")
gala = gala[,-2]
head(gala)
```

### a)
```{r}
gala_pois = glm(Species ~ ., family = poisson, data = gala)
sumary(gala_pois)
```
We can observe that the deviance is 716.85, and the coefficients are relatively small. Area = -5.7994e-04, Elevation = 3.5406e-03, Nearest = 8.8256e-03, Scruz = -5.7094e-03, Adjacent = -6.6303e-04.

\newpage
### b)
$$
\begin{aligned}
\eta &= log(\theta) = log(\mu) \\
\frac{d \eta} {d \mu} &= \frac{1}{\mu} \\
V(\mu) &= \mu \\
w &= \mu \\
z &= log(\mu) + \frac{(y- \mu)}{\mu}
\end{aligned}
$$
The dependent variable has been transformed into z using the taylor series approximation.

\newpage
### c)
```{r}
y = gala$Species
mu = y
eta = log(mu)
d_eta = 1/mu
v = mu
w = mu
z = eta + (y - mu)/mu

lmod = lm(z ~ Area + Elevation + Nearest + Scruz + Adjacent, weights = w, gala)
coef(lmod)
```
We find that the coefficients of the first stage of the iteration are very similar to the Poisson GLM. Rounded to a whole number, the numbers are the same.

\newpage
### d)
```{r}
eta = lmod$fit
mu = exp(eta)
z = eta + (y - mu)/mu
w = mu
lmod = lm(z ~ Area + Elevation + Nearest + Scruz + Adjacent, weights = w, gala)
coef(lmod)

dev = 2*sum(y * log(y) - y * eta - (y - exp(eta)))
dev

coef(gala_pois)
```
The deviance at this stage is larger than the deviance from the GLM and not very close.

\newpage
### e)
```{r}
eta = lmod$fit
mu = exp(eta)
z = eta + (y - mu)/mu
w = mu
lmod = lm(z ~ Area + Elevation + Nearest + Scruz + Adjacent, weights = w, gala)
coef(lmod)

dev = 2*sum(y * log(y) - y * eta - (y - exp(eta)))
dev
```
These estimate are much closer, and are nearly the same as the target

\newpage
### f)
```{r}
# first iteration
eta = lmod$fit
mu = exp(eta)
z = eta + (y - mu)/mu
w = mu
lmod = lm(z ~ Area + Elevation + Nearest + Scruz + Adjacent, weights = w, gala)

dev = 2*sum(y * log(y) - y * eta - (y - exp(eta)))
dev

# second iteration
eta = lmod$fit
mu = exp(eta)
z = eta + (y - mu)/mu
w = mu
lmod = lm(z ~ Area + Elevation + Nearest + Scruz + Adjacent, weights = w, gala)

dev = 2*sum(y * log(y) - y * eta - (y - exp(eta)))
dev

# third iteration
eta = lmod$fit
mu = exp(eta)
z = eta + (y - mu)/mu
w = mu
lmod = lm(z ~ Area + Elevation + Nearest + Scruz + Adjacent, weights = w, gala)

dev = 2*sum(y * log(y) - y * eta - (y - exp(eta)))
dev

coef(lmod)
```
Comparing the final estimated coefficients to those of the GLM, we find that they are identical.

\newpage
### g)
```{r}
summary(lmod)
sumary(gala_pois)
```
While the coefficients are the same, the standard errors are very different to those produced by the GLM fit.

\newpage
## Question 3
```{r}
data(denim)
denim <- denim[-which(denim$waste == max(denim$waste)),] #removing 2 outliers
denim <- denim[-which(denim$waste == max(denim$waste)),]
```

### a)
```{r}
ggplot(aes(x = supplier, y = waste), data = denim) +
  geom_boxplot()
```
From this plot, we can observe that there appears to be a relationship of waste and supplier, with the 5th supplier producing the most waste, and the 1st supplied producing the least on average.

### b)
```{r}
lmod = lm(waste ~ supplier, denim)
summary(lmod)
```
Considering all coefficients are not 0, and the p-value = 0.008, we find that supplier is statistically significant

\newpage

### c)
```{r}
rmod = lmer(waste ~ 1+(1|supplier), denim, REML = TRUE)
summary(rmod)
```
The estimated standard deviation of supplier is 2.391, and the residual standard deviation is 6.107

\newpage
### d)
```{r}
sigma2_alpha = 2.391^2 # var of random intercept
sigma2 = 6.107^2 # var of fixed intercept
corr = sigma2_alpha/(sigma2_alpha + sigma2)
corr
```
The estimated correlation for observations within the same supplier is 0.13

\newpage

### e)
can also do f-test adjusting for effects of freedom
```{r}
nlmod = lm(waste ~ 1, denim)
mmodstar = lmer(waste ~ 1 + (1|supplier), denim, REML = FALSE)
lrt = as.numeric(2*(logLik(mmodstar) - logLik(nlmod)))
```

```{r, message = FALSE}
set.seed(23)
lrt_star = numeric(1000)
for (i in 1:1000) {
  rwaste = unlist(simulate(nlmod))
  nlmodr = lm(rwaste ~ 1, denim)
  mmodr = lmer(rwaste ~ 1 + (1|supplier), denim, REML = FALSE)
  lrt_star[i] = 2*(logLik(mmodr) - logLik(nlmodr))
}

mean(lrt_star > lrt)
```
As p* > p, we fail to reject the null hypothesis, suggesting that we may remove the random effect supplier.

\newpage

## Question 4
```{r}
data(ratdrink, package = "faraway")
```

### a)
```{r}
ggplot(aes(x = weeks, y = wt), data = ratdrink) +
  geom_point() +
  facet_wrap(~treat) 
```
Through this plot, we can observe that as the weeks continue, there is an increase in weight, though the degree to which weight increases appears to vary by treatment.

\newpage

### b)
```{r}
ml = lmer(wt ~ weeks * treat + (weeks | subject), ratdrink)
summary(ml)
```
The fixed effect intercept term represents the initial (week = 0) weight for rats that are in the control group. The interaction term between thiouracil and week suggests that rats in the thiouracil treatment group experience a decrease in weight, compared to the control group, by 9.37 grams as each week passes by. The random effect SD represents the variability in baseline weight across the rats.

\newpage

### c)
```{r}
ml_red = lmer(wt ~ weeks + (weeks | subject), ratdrink)
anova(ml_red, ml)
```
As p < 0.05, we can observe that there is a significant treatment effect

\newpage
### d)
```{r}
fit_val = fitted(ml)
res_val = resid(ml)

plot(fit_val, res_val)

qqnorm(resid(ml))
```
We can observe that there is equal variance and normality through these plots.

\newpage

### e)
```{r}
confint(ml)
```
From the confidence interval, we can gather that the random effect weeks is significant. Furthermore, the thyroxine is not significantly different than the control group.

\newpage

## Question 5
```{r}
data("teengamb")
```

### a)
```{r}
with(teengamb, sm.regression(gamble, income, h = h.select(gamble, income)))
```
This fit is not linear

\newpage

### b)
```{r}
plot(teengamb$gamble ~ teengamb$income, col = gray(0.75), cex.lab = 1.5)
spline_gamb = smooth.spline(teengamb$income, teengamb$gamble)
lines(spline_gamb, lty = 2)

cat("There are", spline_gamb$df, "degrees of freedom")
```

\newpage

### c)
```{r}
plot(teengamb$gamble ~ teengamb$income, col = gray(0.75), cex.lab = 1.5)
spline_gamb_df = smooth.spline(teengamb$income, teengamb$gamble, df = 5)
lines(spline_gamb_df, lty = 2)
```
As the degrees of freedom increases, the curve becomes less smooth. Compared to the results of part b, the automatic choice is not satisfactory, as it is too smooth and fails to capture the general relationship.
